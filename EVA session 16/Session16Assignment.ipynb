{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign16_DNST_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3YMWNcAEmBG",
        "colab_type": "text"
      },
      "source": [
        "## Strategy\n",
        "-  Model architectured to go wider and not deeper.\n",
        "-  Defined tf records class.\n",
        "-  Reached the target accuracy of 85%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTqMKx3EyzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "de61d1a7-56db-431e-d71a-3df55a9e35f0"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9haSYFQFMEj",
        "colab_type": "code",
        "outputId": "b56789ad-2482-4b95-85dc-9e68b106d709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6ZBXE1ZFPSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import sys\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqVXR_v3FhOD",
        "colab_type": "code",
        "outputId": "05e9a106-5653-4552-cb48-66f77ee6165d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLXbkXQus_tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJpqZkisHiAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFRecords:   \n",
        "#   def __init__(self, out_filename, images, labels):\n",
        "#     self.out_filename = out_filename\n",
        "#     self.images = images\n",
        "#     self.labels = labels\n",
        "\n",
        "  def _int64_feature(self, value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "  def _bytes_feature(self, value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "    \n",
        "  def createDataRecord(self, out_filename, images, labels):\n",
        "\n",
        "    writer = tf.io.TFRecordWriter(out_filename)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "      feature = {\n",
        "          'image_raw': self._bytes_feature(images[i].tostring()),\n",
        "          'label': self._int64_feature(labels[i])\n",
        "      }\n",
        "\n",
        "      example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9SvEVJkHum6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantite the class\n",
        "\n",
        "tfRecords = TFRecords()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ51XrLbF2Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfRecords.createDataRecord('train.tfrecords', x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbmbfCyKvnp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfRecords.createDataRecord('test.tfrecords', x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpc_n-RMF5yy",
        "colab_type": "code",
        "outputId": "96670f93-3859-4c44-f79c-3e3f626f704e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test.tfrecords  train.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzd3G_DLre23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 5\n",
        "num_filter = 22\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K01sxNQyrlwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 22, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(5):\n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g2F70PErxK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter = 22, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxcB_S9gr0dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDjAeQSir69v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filter = 22\n",
        "dropout_rate = 0.2\n",
        "l = 5\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBQcqp7sYu3",
        "colab_type": "code",
        "outputId": "04239189-03ed-4e5e-9640-935ea0ed4991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 22)   594         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 22)   88          conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 22)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 22)   4356        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32, 32, 22)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 32, 32, 44)   0           conv2d_52[0][0]                  \n",
            "                                                                 dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 44)   176         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 44)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 22)   8712        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 32, 32, 22)   0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 32, 32, 66)   0           concatenate_48[0][0]             \n",
            "                                                                 dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 66)   264         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 66)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 22)   13068       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32, 32, 22)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 32, 32, 88)   0           concatenate_49[0][0]             \n",
            "                                                                 dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 88)   352         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 88)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 22)   17424       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 32, 32, 22)   0           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 32, 32, 110)  0           concatenate_50[0][0]             \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 110)  440         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 110)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 22)   21780       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 32, 32, 22)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 132)  0           concatenate_51[0][0]             \n",
            "                                                                 dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 132)  528         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 132)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 11)   1452        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 32, 32, 11)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 16, 16, 11)   0           dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 11)   44          average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 11)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 22)   2178        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 22)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 16, 16, 33)   0           average_pooling2d_4[0][0]        \n",
            "                                                                 dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 33)   132         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 33)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 22)   6534        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 22)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 16, 16, 55)   0           concatenate_53[0][0]             \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 55)   220         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 55)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 22)   10890       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 22)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 16, 16, 77)   0           concatenate_54[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 77)   308         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 77)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 22)   15246       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 22)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 16, 16, 99)   0           concatenate_55[0][0]             \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 99)   396         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 99)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 22)   19602       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 22)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 16, 16, 121)  0           concatenate_56[0][0]             \n",
            "                                                                 dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 121)  484         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 121)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 11)   1331        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 16, 16, 11)   0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 8, 8, 11)     0           dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 11)     44          average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 11)     0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 8, 8, 22)     2178        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 8, 8, 22)     0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 8, 8, 33)     0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 33)     132         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 33)     0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 8, 8, 22)     6534        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 8, 8, 22)     0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 8, 8, 55)     0           concatenate_58[0][0]             \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 55)     220         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 55)     0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 22)     10890       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 22)     0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 8, 8, 77)     0           concatenate_59[0][0]             \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 77)     308         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 77)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 22)     15246       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 22)     0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 8, 8, 99)     0           concatenate_60[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 99)     396         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 99)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 22)     19602       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 8, 8, 22)     0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 8, 8, 121)    0           concatenate_61[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 121)    484         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 121)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 11)     1331        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 8, 8, 11)     0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 11)     0           dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 11)     44          average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 11)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 4, 4, 22)     2178        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 4, 4, 22)     0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 4, 4, 33)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 33)     132         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 33)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 4, 4, 22)     6534        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 4, 4, 22)     0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 4, 4, 55)     0           concatenate_63[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 55)     220         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 55)     0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 4, 4, 22)     10890       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 4, 4, 22)     0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 4, 4, 77)     0           concatenate_64[0][0]             \n",
            "                                                                 dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 77)     308         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 77)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 4, 4, 22)     15246       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 4, 4, 22)     0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 4, 4, 99)     0           concatenate_65[0][0]             \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 99)     396         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 99)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 4, 4, 22)     19602       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 4, 4, 22)     0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 4, 4, 121)    0           concatenate_66[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 121)    484         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 121)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 2, 2, 121)    0           activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 484)          0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           4850        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 244,848\n",
            "Trainable params: 241,548\n",
            "Non-trainable params: 3,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9LvsiJ2kyCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ig1ltRPlF66",
        "colab_type": "code",
        "outputId": "4aa73f45-a032-4f2e-95ed-faeee848e7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 22)   594         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 22)   88          conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 22)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 22)   4356        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32, 32, 22)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 32, 32, 44)   0           conv2d_52[0][0]                  \n",
            "                                                                 dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 44)   176         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 44)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 22)   8712        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 32, 32, 22)   0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 32, 32, 66)   0           concatenate_48[0][0]             \n",
            "                                                                 dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 66)   264         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 66)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 22)   13068       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32, 32, 22)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 32, 32, 88)   0           concatenate_49[0][0]             \n",
            "                                                                 dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 88)   352         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 88)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 22)   17424       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 32, 32, 22)   0           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 32, 32, 110)  0           concatenate_50[0][0]             \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 110)  440         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 110)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 22)   21780       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 32, 32, 22)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 132)  0           concatenate_51[0][0]             \n",
            "                                                                 dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 132)  528         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 132)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 11)   1452        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 32, 32, 11)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 16, 16, 11)   0           dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 11)   44          average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 11)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 22)   2178        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 22)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 16, 16, 33)   0           average_pooling2d_4[0][0]        \n",
            "                                                                 dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 33)   132         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 33)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 22)   6534        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 22)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 16, 16, 55)   0           concatenate_53[0][0]             \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 55)   220         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 55)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 22)   10890       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 22)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 16, 16, 77)   0           concatenate_54[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 77)   308         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 77)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 22)   15246       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 22)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 16, 16, 99)   0           concatenate_55[0][0]             \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 99)   396         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 99)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 22)   19602       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 22)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 16, 16, 121)  0           concatenate_56[0][0]             \n",
            "                                                                 dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 121)  484         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 121)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 11)   1331        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 16, 16, 11)   0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 8, 8, 11)     0           dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 11)     44          average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 11)     0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 8, 8, 22)     2178        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 8, 8, 22)     0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 8, 8, 33)     0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 33)     132         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 33)     0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 8, 8, 22)     6534        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 8, 8, 22)     0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 8, 8, 55)     0           concatenate_58[0][0]             \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 55)     220         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 55)     0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 22)     10890       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 22)     0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 8, 8, 77)     0           concatenate_59[0][0]             \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 77)     308         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 77)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 22)     15246       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 22)     0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 8, 8, 99)     0           concatenate_60[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 99)     396         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 99)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 22)     19602       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 8, 8, 22)     0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 8, 8, 121)    0           concatenate_61[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 121)    484         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 121)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 11)     1331        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 8, 8, 11)     0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 11)     0           dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 11)     44          average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 11)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 4, 4, 22)     2178        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 4, 4, 22)     0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 4, 4, 33)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 33)     132         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 33)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 4, 4, 22)     6534        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 4, 4, 22)     0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 4, 4, 55)     0           concatenate_63[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 55)     220         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 55)     0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 4, 4, 22)     10890       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 4, 4, 22)     0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 4, 4, 77)     0           concatenate_64[0][0]             \n",
            "                                                                 dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 77)     308         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 77)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 4, 4, 22)     15246       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 4, 4, 22)     0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 4, 4, 99)     0           concatenate_65[0][0]             \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 99)     396         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 99)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 4, 4, 22)     19602       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 4, 4, 22)     0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 4, 4, 121)    0           concatenate_66[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 121)    484         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 121)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 2, 2, 121)    0           activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 484)          0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           4850        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 244,848\n",
            "Trainable params: 241,548\n",
            "Non-trainable params: 3,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaRv9VibnQWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parser(record):\n",
        "  keys_to_features = {\n",
        "      'image_raw': tf.FixedLenFeature((), tf.string),\n",
        "      'label': tf.FixedLenFeature((), tf.int64)\n",
        "  }\n",
        "  parsed = tf.parse_single_example(record, keys_to_features)\n",
        "  image = tf.decode_raw(parsed['image_raw'], tf.uint8)\n",
        "  image = tf.cast(image, tf.int32)\n",
        "  image = tf.reshape(image, [32,32,3])\n",
        "  label = tf.cast(parsed[\"label\"], tf.int32)\n",
        "  label = tf.one_hot(label, 10)\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xABM6dPRv-dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset_from_TFRecord(filename):\n",
        "  dataset = tf.data.TFRecordDataset(filenames='train.tfrecords')\n",
        "  dataset = dataset.map(parser)\n",
        "  return dataset    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKB7lJtWwT0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = get_dataset_from_TFRecord('train.tfrecords')\n",
        "dataset = dataset.batch(512)\n",
        "dataset = dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bXlAxCnTRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = get_dataset_from_TFRecord('test.tfrecords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LAT2BVynb0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = val_dataset.batch(512).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBk2CP1Gpqfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21687fb3-cdc7-485e-a5ba-391e50c20fef"
      },
      "source": [
        "model.fit(dataset, epochs=50, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,validation_steps=3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 30 steps, validate on 3 steps\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 27s 911ms/step - loss: 1.9842 - acc: 0.2595 - val_loss: 3.2236 - val_acc: 0.1133\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.6350 - acc: 0.3832 - val_loss: 2.0027 - val_acc: 0.2344\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.5326 - acc: 0.4279 - val_loss: 1.8375 - val_acc: 0.3242\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 20s 664ms/step - loss: 1.4176 - acc: 0.4760 - val_loss: 1.5731 - val_acc: 0.4245\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.3611 - acc: 0.5021 - val_loss: 1.3859 - val_acc: 0.4896\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.3273 - acc: 0.5117 - val_loss: 1.5501 - val_acc: 0.4440\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 1.2608 - acc: 0.5370 - val_loss: 1.2996 - val_acc: 0.5293\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.2367 - acc: 0.5488 - val_loss: 1.3328 - val_acc: 0.5260\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.1869 - acc: 0.5671 - val_loss: 1.2787 - val_acc: 0.5443\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 1.1522 - acc: 0.5829 - val_loss: 1.6507 - val_acc: 0.4362\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.1251 - acc: 0.5929 - val_loss: 1.5006 - val_acc: 0.4837\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.0703 - acc: 0.6104 - val_loss: 1.7552 - val_acc: 0.4551\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.0501 - acc: 0.6219 - val_loss: 1.7236 - val_acc: 0.4512\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 1.0256 - acc: 0.6311 - val_loss: 1.0735 - val_acc: 0.6250\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.9816 - acc: 0.6456 - val_loss: 0.9838 - val_acc: 0.6393\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.9810 - acc: 0.6465 - val_loss: 1.2380 - val_acc: 0.5677\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.9307 - acc: 0.6646 - val_loss: 1.4374 - val_acc: 0.5514\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.9254 - acc: 0.6649 - val_loss: 1.1331 - val_acc: 0.6068\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.9136 - acc: 0.6717 - val_loss: 1.0357 - val_acc: 0.6497\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.8806 - acc: 0.6880 - val_loss: 0.9023 - val_acc: 0.6764\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.8725 - acc: 0.6907 - val_loss: 0.8973 - val_acc: 0.6901\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.8451 - acc: 0.6994 - val_loss: 0.9265 - val_acc: 0.6660\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.8363 - acc: 0.7007 - val_loss: 0.8568 - val_acc: 0.6986\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.8289 - acc: 0.7026 - val_loss: 0.9771 - val_acc: 0.6654\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.8171 - acc: 0.7056 - val_loss: 1.0566 - val_acc: 0.6432\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.8141 - acc: 0.7102 - val_loss: 0.9261 - val_acc: 0.6706\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.7727 - acc: 0.7260 - val_loss: 0.8166 - val_acc: 0.7246\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.7684 - acc: 0.7255 - val_loss: 1.2029 - val_acc: 0.6413\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.7758 - acc: 0.7217 - val_loss: 1.0827 - val_acc: 0.6504\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.7465 - acc: 0.7337 - val_loss: 0.8741 - val_acc: 0.7038\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.7473 - acc: 0.7363 - val_loss: 1.0197 - val_acc: 0.6751\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.7396 - acc: 0.7385 - val_loss: 1.1173 - val_acc: 0.6465\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.7207 - acc: 0.7440 - val_loss: 0.7274 - val_acc: 0.7487\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.7132 - acc: 0.7416 - val_loss: 1.1437 - val_acc: 0.6680\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.7128 - acc: 0.7469 - val_loss: 1.2339 - val_acc: 0.6361\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.7001 - acc: 0.7543 - val_loss: 0.8898 - val_acc: 0.7057\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6890 - acc: 0.7532 - val_loss: 0.7579 - val_acc: 0.7266\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6796 - acc: 0.7598 - val_loss: 1.1156 - val_acc: 0.6595\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.6882 - acc: 0.7560 - val_loss: 0.7706 - val_acc: 0.7357\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.6629 - acc: 0.7652 - val_loss: 0.7444 - val_acc: 0.7467\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6704 - acc: 0.7612 - val_loss: 0.6713 - val_acc: 0.7656\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6664 - acc: 0.7626 - val_loss: 0.6752 - val_acc: 0.7520\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.6436 - acc: 0.7688 - val_loss: 0.6995 - val_acc: 0.7591\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6463 - acc: 0.7711 - val_loss: 0.6681 - val_acc: 0.7617\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.6389 - acc: 0.7731 - val_loss: 0.7901 - val_acc: 0.7428\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.6273 - acc: 0.7762 - val_loss: 0.6081 - val_acc: 0.7962\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.6345 - acc: 0.7740 - val_loss: 0.7392 - val_acc: 0.7474\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.6234 - acc: 0.7809 - val_loss: 0.6831 - val_acc: 0.7624\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 17s 581ms/step - loss: 0.6266 - acc: 0.7786 - val_loss: 1.0716 - val_acc: 0.6699\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 18s 591ms/step - loss: 0.6082 - acc: 0.7859 - val_loss: 0.6436 - val_acc: 0.7897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f5e5a67f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7qNpDLrIzrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f79e393-7c2a-46fe-d58a-ede8281446aa"
      },
      "source": [
        "model.fit(dataset, epochs=50, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,validation_steps=3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 30 steps, validate on 3 steps\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 23s 781ms/step - loss: 0.5829 - acc: 0.7927 - val_loss: 0.7560 - val_acc: 0.7474\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.6038 - acc: 0.7894 - val_loss: 0.6978 - val_acc: 0.7604\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.6179 - acc: 0.7801 - val_loss: 0.7244 - val_acc: 0.7578\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.5782 - acc: 0.7959 - val_loss: 0.6073 - val_acc: 0.8034\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5866 - acc: 0.7892 - val_loss: 0.8821 - val_acc: 0.7318\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5898 - acc: 0.7923 - val_loss: 0.9512 - val_acc: 0.7038\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.5568 - acc: 0.8026 - val_loss: 0.5893 - val_acc: 0.7943\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5653 - acc: 0.7986 - val_loss: 0.6219 - val_acc: 0.7884\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5734 - acc: 0.7965 - val_loss: 0.7212 - val_acc: 0.7591\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.5618 - acc: 0.8010 - val_loss: 0.5555 - val_acc: 0.8138\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5448 - acc: 0.8063 - val_loss: 0.5872 - val_acc: 0.8086\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5623 - acc: 0.7998 - val_loss: 0.7569 - val_acc: 0.7461\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5598 - acc: 0.8047 - val_loss: 0.8032 - val_acc: 0.7441\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.5339 - acc: 0.8114 - val_loss: 0.7717 - val_acc: 0.7350\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.5377 - acc: 0.8083 - val_loss: 0.6187 - val_acc: 0.7930\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5536 - acc: 0.8059 - val_loss: 0.6316 - val_acc: 0.7930\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.5239 - acc: 0.8169 - val_loss: 0.7409 - val_acc: 0.7656\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.5436 - acc: 0.8089 - val_loss: 0.5445 - val_acc: 0.8151\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.5297 - acc: 0.8154 - val_loss: 0.5743 - val_acc: 0.8073\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 17s 583ms/step - loss: 0.5099 - acc: 0.8209 - val_loss: 0.4748 - val_acc: 0.8262\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.5153 - acc: 0.8141 - val_loss: 0.7023 - val_acc: 0.7702\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.5226 - acc: 0.8184 - val_loss: 0.6266 - val_acc: 0.7910\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.5119 - acc: 0.8190 - val_loss: 0.6273 - val_acc: 0.8001\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5056 - acc: 0.8212 - val_loss: 0.7036 - val_acc: 0.7721\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.5065 - acc: 0.8227 - val_loss: 0.7520 - val_acc: 0.7689\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.5196 - acc: 0.8161 - val_loss: 0.6710 - val_acc: 0.7812\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 17s 583ms/step - loss: 0.4897 - acc: 0.8242 - val_loss: 0.6000 - val_acc: 0.8040\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.5005 - acc: 0.8227 - val_loss: 0.6332 - val_acc: 0.8001\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.5030 - acc: 0.8225 - val_loss: 0.6385 - val_acc: 0.7897\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.4807 - acc: 0.8282 - val_loss: 0.5810 - val_acc: 0.8073\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.4917 - acc: 0.8253 - val_loss: 0.4758 - val_acc: 0.8424\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4852 - acc: 0.8304 - val_loss: 1.4102 - val_acc: 0.6569\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.4824 - acc: 0.8310 - val_loss: 0.5007 - val_acc: 0.8314\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.4762 - acc: 0.8320 - val_loss: 0.5622 - val_acc: 0.8171\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4819 - acc: 0.8322 - val_loss: 0.6437 - val_acc: 0.7780\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 18s 584ms/step - loss: 0.4715 - acc: 0.8329 - val_loss: 0.5610 - val_acc: 0.8177\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4610 - acc: 0.8356 - val_loss: 0.4951 - val_acc: 0.8320\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.4737 - acc: 0.8336 - val_loss: 0.4603 - val_acc: 0.8444\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.4779 - acc: 0.8318 - val_loss: 0.5589 - val_acc: 0.8151\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 17s 583ms/step - loss: 0.4445 - acc: 0.8416 - val_loss: 0.4998 - val_acc: 0.8307\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4607 - acc: 0.8371 - val_loss: 0.7165 - val_acc: 0.7682\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 0.4688 - acc: 0.8354 - val_loss: 1.0606 - val_acc: 0.7038\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.4563 - acc: 0.8390 - val_loss: 0.4899 - val_acc: 0.8229\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4603 - acc: 0.8370 - val_loss: 0.5263 - val_acc: 0.8294\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 0.4435 - acc: 0.8439 - val_loss: 0.6360 - val_acc: 0.8014\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 18s 585ms/step - loss: 0.4470 - acc: 0.8442 - val_loss: 0.6923 - val_acc: 0.7845\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.4507 - acc: 0.8423 - val_loss: 0.4256 - val_acc: 0.8555\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 0.4490 - acc: 0.8395 - val_loss: 0.5072 - val_acc: 0.8255\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 18s 583ms/step - loss: 0.4413 - acc: 0.8437 - val_loss: 0.6166 - val_acc: 0.7917\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 0.4310 - acc: 0.8469 - val_loss: 0.6259 - val_acc: 0.8047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f5e5e7d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}